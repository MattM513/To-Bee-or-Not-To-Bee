{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52418898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Predictions for \"To bee or not to bee\"\n",
    "# Generate predictions for images 251-347\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from skimage import measure, feature, color, morphology\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score, silhouette_score\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, Isomap\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from skimage.transform import rotate\n",
    "\n",
    "# Configuration des chemins\n",
    "DATA_DIR = \"../../test\" \n",
    "IMAGES_DIR = os.path.join(DATA_DIR, \"images\")\n",
    "MASKS_DIR = os.path.join(DATA_DIR, \"masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02e07f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image_filled(image, angle, center):\n",
    "    \"\"\"Just rotates the image in memory for symmetry calculation\"\"\"\n",
    "    try:\n",
    "        center_skimage = (center[1], center[0])\n",
    "        rotated = rotate(image, angle, center=center_skimage, preserve_range=True, cval=0)\n",
    "        return rotated.astype(image.dtype)\n",
    "    except Exception as e:\n",
    "        print(f\"Rotation error: {e}\")\n",
    "        return image\n",
    "\n",
    "def create_symmetric_image(image, center_x):\n",
    "    \"\"\"Just flips the image in memory for symmetry calculation\"\"\"\n",
    "    symmetric_image = np.fliplr(image)\n",
    "    return symmetric_image\n",
    "\n",
    "def load_image_and_mask(image_id, visualize=False, output_dir=\"../cleaned_samples\"):\n",
    "    \"\"\"\n",
    "    I. Quality control: Load and clean an image and its mask according to instructions:\n",
    "    - Loading the mask and associated image\n",
    "    - Transforming the mask into a binary image (label 1 being the insect, label 0 the background)\n",
    "    - Computing the connected components of the binary mask\n",
    "    - Restricting the binary mask to its connected component of highest area\n",
    "    - Restricting both mask and image to the bounding box of the cleaned binary mask\n",
    "    \"\"\"\n",
    "    image_path = os.path.join(IMAGES_DIR, f\"{image_id}.jpg\")\n",
    "    mask_path = os.path.join(MASKS_DIR, f\"binary_{image_id}.tif\")\n",
    "\n",
    "    # Check file existence\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "    if not os.path.exists(mask_path):\n",
    "        raise FileNotFoundError(f\"Mask not found: {mask_path}\")\n",
    "\n",
    "    # Loading the mask and associated image\n",
    "    image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
    "    mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "    \n",
    "    # Transforming the mask into a binary image\n",
    "    mask_binary = (mask > 0).astype(np.uint8)\n",
    "\n",
    "    # Computing the connected components of the binary mask\n",
    "    labeled_mask = measure.label(mask_binary)\n",
    "    props = measure.regionprops(labeled_mask)\n",
    "\n",
    "    if not props:\n",
    "        raise ValueError(f\"No connected components found in mask for image {image_id}\")\n",
    "\n",
    "    # Restricting to largest connected component\n",
    "    largest_region = max(props, key=lambda x: x.area)\n",
    "    cleaned_mask = (labeled_mask == largest_region.label).astype(np.uint8)\n",
    "\n",
    "    # Cropping to bounding box\n",
    "    minr, minc, maxr, maxc = largest_region.bbox\n",
    "    cleaned_mask_cropped = cleaned_mask[minr:maxr, minc:maxc]\n",
    "    cropped_image = image[minr:maxr, minc:maxc]\n",
    "\n",
    "    # Visualization\n",
    "    if visualize:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        \n",
    "        # Original Image\n",
    "        axes[0,0].imshow(image)\n",
    "        axes[0,0].set_title(f\"Original Image {image_id}\")\n",
    "        axes[0,0].axis('off')\n",
    "        \n",
    "        # Original Mask\n",
    "        axes[0,1].imshow(mask, cmap='gray')\n",
    "        axes[0,1].set_title(\"Original Mask\")\n",
    "        axes[0,1].axis('off')\n",
    "        \n",
    "        # Cleaned & Cropped Image\n",
    "        axes[1,0].imshow(cropped_image)\n",
    "        axes[1,0].set_title(\"Cleaned & Cropped Image\")\n",
    "        axes[1,0].axis('off')\n",
    "        \n",
    "        # Cleaned & Cropped Mask\n",
    "        axes[1,1].imshow(cleaned_mask_cropped, cmap='gray')\n",
    "        axes[1,1].set_title(\"Cleaned & Cropped Mask\")\n",
    "        axes[1,1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"quality_control_{image_id}.png\"), dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    return cropped_image, cleaned_mask_cropped\n",
    "\n",
    "\n",
    "def compute_best_inscribed_circle(mask):\n",
    "    \"\"\"\n",
    "    II. Computation of the best inscribed circle:\n",
    "    - Choosing a proper initialization relying on the centroid of the mask\n",
    "    - Defining a loss function to minimize\n",
    "    - Minimizing the defined loss using the minimize function of Scipy\n",
    "    \"\"\"\n",
    "    from scipy.ndimage import distance_transform_edt\n",
    "    \n",
    "    mask_binary = (mask > 0).astype(int)\n",
    "    if not np.any(mask_binary):\n",
    "        return 0.0, (0.0, 0.0)\n",
    "    \n",
    "    # Distance transform to find distance to nearest edge\n",
    "    distance_map = distance_transform_edt(mask_binary)\n",
    "    \n",
    "    # Initialize with centroid\n",
    "    props = measure.regionprops(mask_binary)\n",
    "    if not props:\n",
    "        return 0.0, (0.0, 0.0)\n",
    "    \n",
    "    centroid = props[0].centroid  # (y, x)\n",
    "    \n",
    "    # Loss function: negative radius (to maximize radius)\n",
    "    def loss_function(coords):\n",
    "        y, x = coords\n",
    "        if not (0 <= y < distance_map.shape[0] and 0 <= x < distance_map.shape[1]):\n",
    "            return 1000  # Penalty for out of bounds\n",
    "        \n",
    "        radius = distance_map[int(y), int(x)]\n",
    "        return -radius  # Negative because we want to maximize\n",
    "    \n",
    "    # Minimize using scipy\n",
    "    result = minimize(\n",
    "        loss_function,\n",
    "        x0=[centroid[0], centroid[1]],\n",
    "        bounds=[(0, mask_binary.shape[0]-1), (0, mask_binary.shape[1]-1)],\n",
    "        method='L-BFGS-B'\n",
    "    )\n",
    "    \n",
    "    y_opt, x_opt = result.x[0], result.x[1]\n",
    "    max_radius = -result.fun\n",
    "    best_center = (x_opt, y_opt)  # Return as (x, y)\n",
    "    \n",
    "    return float(max_radius), best_center\n",
    "\n",
    "def compute_best_symmetry_plane(image, mask, circle_center, circle_radius):\n",
    "    \"\"\"\n",
    "    III. Computation of the best symmetry plane:\n",
    "    - Choosing a proper initialization among rotations\n",
    "    - Using the filled and proper rotation function\n",
    "    - Using function to create symmetric around vertical line\n",
    "    - Defining a loss function to minimize\n",
    "    - Minimizing using scipy.minimize\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create circular mask for region of interest\n",
    "    Y, X = np.ogrid[:mask.shape[0], :mask.shape[1]]\n",
    "    cx, cy = circle_center\n",
    "    circle_mask = (X - cx)**2 + (Y - cy)**2 <= circle_radius**2\n",
    "    \n",
    "    # Loss function based on difference between image and its symmetric\n",
    "    def symmetry_loss_function(angle):\n",
    "        try:\n",
    "            # Rotate image\n",
    "            rotated_image = rotate_image_filled(image, angle[0], circle_center)\n",
    "            # Create symmetric image\n",
    "            symmetric_image = create_symmetric_image(rotated_image, cx)\n",
    "            \n",
    "            # Calculate difference in circular region\n",
    "            if np.any(circle_mask):\n",
    "                diff = np.sum((rotated_image[circle_mask].astype(float) - \n",
    "                              symmetric_image[circle_mask].astype(float))**2)\n",
    "                return diff / np.sum(circle_mask)\n",
    "            else:\n",
    "                return 1000\n",
    "        except Exception as e:\n",
    "            return 1000\n",
    "    \n",
    "    # Try multiple initial angles\n",
    "    initial_angles = [-30, -15, 0, 15, 30]\n",
    "    best_result = None\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for init_angle in initial_angles:\n",
    "        try:\n",
    "            result = minimize(\n",
    "                symmetry_loss_function,\n",
    "                x0=[init_angle],\n",
    "                bounds=[(-45, 45)],\n",
    "                method='L-BFGS-B'\n",
    "            )\n",
    "            \n",
    "            if result.fun < best_loss:\n",
    "                best_loss = result.fun\n",
    "                best_result = result\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if best_result is not None:\n",
    "        best_angle = best_result.x[0]\n",
    "        min_loss = best_result.fun\n",
    "    else:\n",
    "        best_angle = 0.0\n",
    "        min_loss = 1000.0\n",
    "    \n",
    "    return float(min_loss), float(best_angle)\n",
    "\n",
    "def extract_shape_features(mask):\n",
    "    \"\"\"Extract shape features from mask\"\"\"\n",
    "    mask_binary = (mask > 0).astype(int)\n",
    "    \n",
    "    props = measure.regionprops(mask_binary)\n",
    "    if not props:\n",
    "        return {\n",
    "            'area': 0, 'perimeter': 0, 'eccentricity': 0, 'solidity': 0, \n",
    "            'extent': 0, 'aspect_ratio': 0, 'horizontal_symmetry': 0\n",
    "        }\n",
    "    \n",
    "    prop = props[0]\n",
    "    \n",
    "    # Basic shape features\n",
    "    area = prop.area\n",
    "    perimeter = prop.perimeter\n",
    "    eccentricity = prop.eccentricity\n",
    "    solidity = prop.solidity\n",
    "    extent = prop.extent\n",
    "    \n",
    "    # Aspect ratio\n",
    "    major_axis_length = prop.major_axis_length\n",
    "    minor_axis_length = prop.minor_axis_length\n",
    "    aspect_ratio = major_axis_length / minor_axis_length if minor_axis_length > 0 else 0\n",
    "    \n",
    "    # Horizontal symmetry measure\n",
    "    height, width = mask_binary.shape\n",
    "    if width >= 2:\n",
    "        mid = width // 2\n",
    "        left_half = mask_binary[:, :mid]\n",
    "        right_half = mask_binary[:, width-mid:]\n",
    "        right_half_flipped = np.fliplr(right_half)\n",
    "        \n",
    "        min_width = min(left_half.shape[1], right_half_flipped.shape[1])\n",
    "        if min_width > 0:\n",
    "            intersection = np.sum(left_half[:, :min_width] & right_half_flipped[:, :min_width])\n",
    "            union = np.sum(left_half[:, :min_width] | right_half_flipped[:, :min_width])\n",
    "            horizontal_symmetry = intersection / union if union > 0 else 0\n",
    "        else:\n",
    "            horizontal_symmetry = 0\n",
    "    else:\n",
    "        horizontal_symmetry = 0\n",
    "    \n",
    "    return {\n",
    "        'area': float(area),\n",
    "        'perimeter': float(perimeter),\n",
    "        'eccentricity': float(eccentricity),\n",
    "        'solidity': float(solidity),\n",
    "        'extent': float(extent),\n",
    "        'aspect_ratio': float(aspect_ratio),\n",
    "        'horizontal_symmetry': float(horizontal_symmetry)\n",
    "    }\n",
    "\n",
    "def calculate_bug_ratio(mask):\n",
    "    \"\"\"Calculate ratio of bug pixels to total pixels\"\"\"\n",
    "    bug_pixels = np.sum(mask > 0)\n",
    "    total_pixels = mask.size\n",
    "    ratio = bug_pixels / total_pixels if total_pixels > 0 else 0\n",
    "    return float(ratio)\n",
    "\n",
    "def extract_color_features(image, mask):\n",
    "    \"\"\"Extract color features (RGB) from image within mask\"\"\"\n",
    "    mask_bool = mask > 0\n",
    "    \n",
    "    if not np.any(mask_bool):\n",
    "        return {f'{color}_{stat}': 0.0 for color in ['r', 'g', 'b'] \n",
    "                for stat in ['min', 'max', 'mean', 'median', 'std']}\n",
    "    \n",
    "    # Extract pixels within mask for each channel\n",
    "    r_channel = image[:, :, 0][mask_bool]\n",
    "    g_channel = image[:, :, 1][mask_bool]\n",
    "    b_channel = image[:, :, 2][mask_bool]\n",
    "    \n",
    "    def get_channel_stats(channel):\n",
    "        if len(channel) == 0:\n",
    "            return {'min': 0, 'max': 0, 'mean': 0, 'median': 0, 'std': 0}\n",
    "        return {\n",
    "            'min': float(np.min(channel)),\n",
    "            'max': float(np.max(channel)),\n",
    "            'mean': float(np.mean(channel)),\n",
    "            'median': float(np.median(channel)),\n",
    "            'std': float(np.std(channel))\n",
    "        }\n",
    "    \n",
    "    # Get stats for each channel\n",
    "    r_stats = get_channel_stats(r_channel)\n",
    "    g_stats = get_channel_stats(g_channel)\n",
    "    b_stats = get_channel_stats(b_channel)\n",
    "    \n",
    "    color_features = {}\n",
    "    for stat in ['min', 'max', 'mean', 'median', 'std']:\n",
    "        color_features[f'r_{stat}'] = r_stats[stat]\n",
    "        color_features[f'g_{stat}'] = g_stats[stat]\n",
    "        color_features[f'b_{stat}'] = b_stats[stat]\n",
    "    \n",
    "    return color_features\n",
    "\n",
    "def extract_additional_features(image, mask):\n",
    "    \"\"\"Extract additional features (texture and Hu moments)\"\"\"\n",
    "    mask_bool = mask > 0\n",
    "    \n",
    "    if not np.any(mask_bool):\n",
    "        return {\n",
    "            'texture_entropy': 0.0, 'texture_energy': 0.0,\n",
    "            'hu_moment1': 0.0, 'hu_moment2': 0.0, 'hu_moment3': 0.0, 'hu_moment4': 0.0\n",
    "        }\n",
    "    \n",
    "    # Texture features using Local Binary Pattern\n",
    "    try:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        radius = min(3, min(image.shape[:2]) // 4)\n",
    "        n_points = 8 * radius\n",
    "        \n",
    "        if radius > 0:\n",
    "            lbp = feature.local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "            lbp_bug = lbp[mask_bool]\n",
    "            \n",
    "            if len(lbp_bug) > 0:\n",
    "                n_bins = int(n_points + 2)\n",
    "                hist, _ = np.histogram(lbp_bug, bins=n_bins, range=(0, n_bins), density=True)\n",
    "                hist = hist + 1e-10\n",
    "                texture_entropy = -np.sum(hist * np.log2(hist))\n",
    "                texture_energy = np.sum(hist ** 2)\n",
    "            else:\n",
    "                texture_entropy = 0.0\n",
    "                texture_energy = 0.0\n",
    "        else:\n",
    "            texture_entropy = 0.0\n",
    "            texture_energy = 0.0\n",
    "    except:\n",
    "        texture_entropy = 0.0\n",
    "        texture_energy = 0.0\n",
    "    \n",
    "    # Hu moments\n",
    "    try:\n",
    "        moments = cv2.moments(mask.astype(np.uint8))\n",
    "        hu_moments = cv2.HuMoments(moments).flatten()\n",
    "        \n",
    "        hu_moments_safe = []\n",
    "        for moment in hu_moments[:4]:\n",
    "            if abs(moment) < 1e-10:\n",
    "                hu_moments_safe.append(0.0)\n",
    "            else:\n",
    "                hu_moments_safe.append(-np.sign(moment) * np.log10(abs(moment)))\n",
    "        \n",
    "        while len(hu_moments_safe) < 4:\n",
    "            hu_moments_safe.append(0.0)\n",
    "    except:\n",
    "        hu_moments_safe = [0.0, 0.0, 0.0, 0.0]\n",
    "    \n",
    "    return {\n",
    "        'texture_entropy': float(texture_entropy),\n",
    "        'texture_energy': float(texture_energy),\n",
    "        'hu_moment1': float(hu_moments_safe[0]),\n",
    "        'hu_moment2': float(hu_moments_safe[1]),\n",
    "        'hu_moment3': float(hu_moments_safe[2]),\n",
    "        'hu_moment4': float(hu_moments_safe[3])\n",
    "    }\n",
    "\n",
    "def create_default_features(image_id):\n",
    "    \"\"\"Create default features when extraction fails\"\"\"\n",
    "    return {\n",
    "        'image_id': int(image_id),\n",
    "        'bug_ratio': 0.0,\n",
    "        'max_inscribed_radius': 0.0,\n",
    "        'symmetry_score': 0.0,\n",
    "        'symmetry_angle': 0.0,\n",
    "        'area': 0.0, 'perimeter': 0.0, 'eccentricity': 0.0, 'solidity': 0.0,\n",
    "        'extent': 0.0, 'aspect_ratio': 0.0, 'horizontal_symmetry': 0.0,\n",
    "        **{f'{color}_{stat}': 0.0 for color in ['r', 'g', 'b'] \n",
    "           for stat in ['min', 'max', 'mean', 'median', 'std']},\n",
    "        'texture_entropy': 0.0, 'texture_energy': 0.0,\n",
    "        'hu_moment1': 0.0, 'hu_moment2': 0.0, 'hu_moment3': 0.0, 'hu_moment4': 0.0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37a69c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEST SET PREDICTIONS (Images 251-347) ===\n",
      "\n",
      "1. Loading models and preprocessors...\n",
      "✓ Models loaded successfully\n",
      "✓ Using 32 features\n",
      "\n",
      "2. Extracting features for test images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 97/97 [21:30<00:00, 13.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully processed 97 images\n",
      "\n",
      "3. Normalizing features...\n",
      "\n",
      "4. Generating predictions...\n",
      "\n",
      "5. Prediction Summary:\n",
      "----------------------------------------\n",
      "bug type\n",
      "Bee          49\n",
      "Bumblebee    30\n",
      "Butterfly     7\n",
      "Wasp          6\n",
      "Hover fly     5\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "✓ Predictions saved to: ../predictions_test.csv\n",
      "✓ File contains 97 predictions\n",
      "\n",
      "6. Submission file verification:\n",
      "  - Columns: ['ID', 'bug type']\n",
      "  - ID range: 251 to 347\n",
      "  - Unique bug types: ['Bee', 'Bumblebee', 'Butterfly', 'Hover fly', 'Wasp']\n",
      "  - Shape: (97, 2)\n",
      "\n",
      "First 10 predictions:\n",
      "    ID   bug type\n",
      "0  251        Bee\n",
      "1  252        Bee\n",
      "2  253  Hover fly\n",
      "3  254  Butterfly\n",
      "4  255        Bee\n",
      "5  256        Bee\n",
      "6  257        Bee\n",
      "7  258        Bee\n",
      "8  259        Bee\n",
      "9  260        Bee\n",
      "\n",
      "✅ TEST PREDICTIONS COMPLETE!\n",
      "📁 Submit the file: ../predictions_test.csv\n"
     ]
    }
   ],
   "source": [
    "# For now, I'll provide a template function\n",
    "def extract_all_features_test(image_id, test_dir=\"../../test\"):\n",
    "    \"\"\"\n",
    "    Extract all features for a test image\n",
    "    This should be identical to your training feature extraction\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load image and mask\n",
    "        image_path = os.path.join(test_dir, \"images\", f\"{image_id}.jpg\")\n",
    "        mask_path = os.path.join(test_dir, \"masks\", f\"binary_{image_id}.tif\")\n",
    "        \n",
    "        # Check if files exist\n",
    "        if not os.path.exists(image_path) or not os.path.exists(mask_path):\n",
    "            print(f\"Missing files for image {image_id}\")\n",
    "            return create_default_features(image_id)\n",
    "        \n",
    "        # Load and process (you need to use your actual functions here)\n",
    "         # Load directly for test data\n",
    "        image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "\n",
    "        # Apply same preprocessing as training\n",
    "        mask_binary = (mask > 0).astype(np.uint8)\n",
    "        labeled_mask = measure.label(mask_binary)\n",
    "        props = measure.regionprops(labeled_mask)\n",
    "\n",
    "        if props:\n",
    "            largest_region = max(props, key=lambda x: x.area)\n",
    "            cleaned_mask = (labeled_mask == largest_region.label).astype(np.uint8)\n",
    "            minr, minc, maxr, maxc = largest_region.bbox\n",
    "            mask = cleaned_mask[minr:maxr, minc:maxc]\n",
    "            image = image[minr:maxr, minc:maxc]\n",
    "        else:\n",
    "            return create_default_features(image_id)\n",
    "        \n",
    "        # Extract all features\n",
    "        shape_features = extract_shape_features(mask)\n",
    "        bug_ratio = calculate_bug_ratio(mask)\n",
    "        color_features = extract_color_features(image, mask)\n",
    "        additional_features = extract_additional_features(image, mask)\n",
    "        \n",
    "        # Compute inscribed circle and symmetry\n",
    "        max_radius, circle_center = compute_best_inscribed_circle(mask)\n",
    "        \n",
    "        if max_radius > 5:\n",
    "            symmetry_score, symmetry_angle = compute_best_symmetry_plane(\n",
    "                image, mask, circle_center, max_radius\n",
    "            )\n",
    "        else:\n",
    "            symmetry_score = 0.0\n",
    "            symmetry_angle = 0.0\n",
    "        \n",
    "        # Combine all features\n",
    "        features = {\n",
    "            'image_id': int(image_id),\n",
    "            'bug_ratio': bug_ratio,\n",
    "            'max_inscribed_radius': max_radius,\n",
    "            'symmetry_score': symmetry_score,\n",
    "            'symmetry_angle': symmetry_angle,\n",
    "            **shape_features,\n",
    "            **color_features,\n",
    "            **additional_features\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_id}: {e}\")\n",
    "        return create_default_features(image_id)\n",
    "\n",
    "# ==================== MAIN PREDICTION PIPELINE ====================\n",
    "\n",
    "def main():\n",
    "    print(\"=== TEST SET PREDICTIONS (Images 251-347) ===\\n\")\n",
    "    \n",
    "    # 1. Load saved models and preprocessors\n",
    "    print(\"1. Loading models and preprocessors...\")\n",
    "    try:\n",
    "        best_model = joblib.load('models/best_model.pkl')\n",
    "        scaler = joblib.load('../scaler.pkl')  # From feature extraction\n",
    "        label_encoder = joblib.load('models/label_encoder.pkl')\n",
    "        print(\"✓ Models loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading models: {e}\")\n",
    "        print(\"Make sure you have run the ML notebook and feature extraction first!\")\n",
    "        return\n",
    "    \n",
    "    # 2. Get feature columns from training data\n",
    "    train_features = pd.read_csv('../features_normalized.csv')\n",
    "    feature_cols = [col for col in train_features.columns \n",
    "                   if col not in ['image_id', 'bug_type', 'species']]\n",
    "    print(f\"✓ Using {len(feature_cols)} features\")\n",
    "    \n",
    "    # 3. Extract features for test images\n",
    "    print(\"\\n2. Extracting features for test images...\")\n",
    "    test_features = []\n",
    "    failed_images = []\n",
    "    \n",
    "    for image_id in tqdm(range(251, 348), desc=\"Processing images\"):\n",
    "        features = extract_all_features_test(image_id)\n",
    "        if features is not None:\n",
    "            test_features.append(features)\n",
    "        else:\n",
    "            failed_images.append(image_id)\n",
    "    \n",
    "    print(f\"✓ Successfully processed {len(test_features)} images\")\n",
    "    if failed_images:\n",
    "        print(f\"⚠️  Failed to process {len(failed_images)} images: {failed_images}\")\n",
    "    \n",
    "    # 4. Create DataFrame and ensure column consistency\n",
    "    test_df = pd.DataFrame(test_features)\n",
    "    \n",
    "    # Ensure all required columns are present\n",
    "    missing_cols = set(feature_cols) - set(test_df.columns)\n",
    "    if missing_cols:\n",
    "        print(f\"\\n⚠️  Adding missing columns with default values: {missing_cols}\")\n",
    "        for col in missing_cols:\n",
    "            test_df[col] = 0.0\n",
    "    \n",
    "    # Select features in the same order as training\n",
    "    X_test = test_df[feature_cols].values\n",
    "    \n",
    "    # 5. Normalize features\n",
    "    print(\"\\n3. Normalizing features...\")\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "    \n",
    "    # 6. Generate predictions\n",
    "    print(\"\\n4. Generating predictions...\")\n",
    "    predictions_encoded = best_model.predict(X_test_normalized)\n",
    "    predictions = label_encoder.inverse_transform(predictions_encoded)\n",
    "    \n",
    "    # 7. Create submission DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'ID': test_df['image_id'].astype(int),\n",
    "        'bug type': predictions\n",
    "    })\n",
    "    \n",
    "    # Sort by ID to ensure correct order\n",
    "    submission_df = submission_df.sort_values('ID')\n",
    "    \n",
    "    # 8. Display prediction summary\n",
    "    print(\"\\n5. Prediction Summary:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(submission_df['bug type'].value_counts())\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Check for any suspicious predictions\n",
    "    if 'Bee & Bumblebee' in submission_df['bug type'].values:\n",
    "        count = (submission_df['bug type'] == 'Bee & Bumblebee').sum()\n",
    "        print(f\"\\n⚠️  Warning: {count} images predicted as 'Bee & Bumblebee'\")\n",
    "        print(\"This rare class had only 1 training sample - predictions may be unreliable\")\n",
    "    \n",
    "    # 9. Save submission file\n",
    "    output_path = '../predictions_test.csv'\n",
    "    submission_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\n✓ Predictions saved to: {output_path}\")\n",
    "    print(f\"✓ File contains {len(submission_df)} predictions\")\n",
    "    \n",
    "    # 10. Verify submission format\n",
    "    print(\"\\n6. Submission file verification:\")\n",
    "    print(f\"  - Columns: {list(submission_df.columns)}\")\n",
    "    print(f\"  - ID range: {submission_df['ID'].min()} to {submission_df['ID'].max()}\")\n",
    "    print(f\"  - Unique bug types: {sorted(submission_df['bug type'].unique())}\")\n",
    "    print(f\"  - Shape: {submission_df.shape}\")\n",
    "    \n",
    "    # Display first few predictions\n",
    "    print(\"\\nFirst 10 predictions:\")\n",
    "    print(submission_df.head(10))\n",
    "    \n",
    "    print(\"\\n✅ TEST PREDICTIONS COMPLETE!\")\n",
    "    print(f\"📁 Submit the file: {output_path}\")\n",
    "\n",
    "# ==================== ALTERNATIVE: BATCH PREDICTION ====================\n",
    "\n",
    "def predict_from_existing_features(test_features_path):\n",
    "    \"\"\"\n",
    "    Alternative method if you've already extracted test features\n",
    "    \"\"\"\n",
    "    print(\"=== PREDICTIONS FROM EXISTING FEATURES ===\\n\")\n",
    "    \n",
    "    # Load models\n",
    "    best_model = joblib.load('models/best_model.pkl')\n",
    "    scaler = joblib.load('../scaler.pkl')\n",
    "    label_encoder = joblib.load('models/label_encoder.pkl')\n",
    "    \n",
    "    # Load test features\n",
    "    test_df = pd.read_csv(test_features_path)\n",
    "    \n",
    "    # Get feature columns\n",
    "    train_features = pd.read_csv('../features_normalized.csv')\n",
    "    feature_cols = [col for col in train_features.columns \n",
    "                   if col not in ['image_id', 'bug_type', 'species']]\n",
    "    \n",
    "    # Prepare data\n",
    "    X_test = test_df[feature_cols].values\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "    \n",
    "    # Predict\n",
    "    predictions_encoded = best_model.predict(X_test_normalized)\n",
    "    predictions = label_encoder.inverse_transform(predictions_encoded)\n",
    "    \n",
    "    # Create submission\n",
    "    submission_df = pd.DataFrame({\n",
    "        'ID': test_df['image_id'].astype(int),\n",
    "        'bug type': predictions\n",
    "    })\n",
    "    \n",
    "    submission_df.to_csv('../predictions_test.csv', index=False)\n",
    "    print(f\"✓ Predictions saved to: ../predictions_test.csv\")\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "# ==================== RUN THE PREDICTION ====================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Option 1: Extract features and predict\n",
    "    main()\n",
    "    \n",
    "    # Option 2: If you have already extracted test features to a CSV file\n",
    "    # test_features_path = '../test_features.csv'\n",
    "    # if os.path.exists(test_features_path):\n",
    "    #     predict_from_existing_features(test_features_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
